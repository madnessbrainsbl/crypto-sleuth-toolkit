#!/usr/bin/env python3
"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–∏–Ω–∞—Ä–Ω–∏–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–∫—Ä—ã—Ç—ã—Ö/–æ–±—Ñ—É—Å—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª—é—á–µ–π
"""

import jwt
import hashlib
import hmac
import struct
import binascii
import base64
import os
import re
from itertools import combinations

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
WORKING_TOKEN = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ2ZWhpY2xlX2lkIjoiMGQ3OWZmMDQ3ZjVjZWM1YmYyZWMyZWM3ZDNlNDY0Y2UiLCJpc3MiOiJDdW5CQSIsInRpbWVzdGFtcCI6MTc1MzA5NjIwMn0.MWlqDVyQK4lhpZNZgaBS6gHisirYceGIxWvb9Q1-zXw"
EXACT_PAYLOAD = {
    "vehicle_id": "0d79ff047f5cec5bf2ec2ec7d3e464ce",
    "iss": "CunBA",
    "timestamp": 1753096202
}

def test_key_candidate(key):
    """–¢–µ—Å—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∫–ª—é—á–∞"""
    try:
        test_token = jwt.encode(EXACT_PAYLOAD, key, algorithm='HS256')
        return test_token == WORKING_TOKEN
    except:
        return False

def find_hidden_strings():
    """–ü–æ–∏—Å–∫ —Å–∫—Ä—ã—Ç—ã—Ö —Å—Ç—Ä–æ–∫ —á–µ—Ä–µ–∑ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üîç –ü–û–ò–°–ö –°–ö–†–´–¢–´–• –°–¢–†–û–ö")
    print("="*50)
    
    candidates = set()
    
    try:
        with open("unlock", "rb") as f:
            data = f.read()
        
        print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {len(data)} –±–∞–π—Ç")
        
        # 1. –ü–æ–∏—Å–∫ Base64 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –≤ —Å—ã—Ä–æ–º –≤–∏–¥–µ
        print("\nüî§ –ü–æ–∏—Å–∫ Base64 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π...")
        b64_pattern = re.compile(rb'[A-Za-z0-9+/]{20,}={0,2}')
        b64_matches = b64_pattern.findall(data)
        
        for match in b64_matches:
            try:
                decoded = base64.b64decode(match).decode('ascii', errors='ignore')
                if len(decoded) >= 8 and decoded.isprintable():
                    candidates.add(decoded)
                    print(f"   Base64: {match.decode()[:50]}... -> {decoded}")
            except:
                pass
        
        # 2. –ü–æ–∏—Å–∫ Hex-–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        print("\nüî¢ –ü–æ–∏—Å–∫ Hex –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π...")
        hex_pattern = re.compile(rb'[0-9a-fA-F]{32,}')
        hex_matches = hex_pattern.findall(data)
        
        for match in hex_matches[:20]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–≤–æ–¥
            try:
                hex_str = match.decode('ascii')
                if len(hex_str) % 2 == 0:
                    decoded_bytes = binascii.unhexlify(hex_str)
                    decoded = decoded_bytes.decode('ascii', errors='ignore')
                    if len(decoded) >= 4 and decoded.isprintable():
                        candidates.add(decoded)
                        print(f"   Hex: {hex_str[:50]}... -> {decoded}")
            except:
                pass
        
        # 3. –ü–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫ –≤ —Ä–∞–∑–Ω—ã—Ö –∫–æ–¥–∏—Ä–æ–≤–∫–∞—Ö
        print("\nüåê –ü–æ–∏—Å–∫ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–¥–∏—Ä–æ–≤–∫–∞—Ö...")
        encodings = ['utf-8', 'latin1', 'ascii', 'utf-16', 'utf-32']
        
        for encoding in encodings:
            try:
                text = data.decode(encoding, errors='ignore')
                # –ò—â–µ–º –¥–ª–∏–Ω–Ω—ã–µ –∞–ª—Ñ–∞–Ω—É–º–µ—Ä–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                words = re.findall(r'[A-Za-z0-9+/=_-]{16,64}', text)
                for word in words[:100]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
                    candidates.add(word)
            except:
                continue
        
        # 4. XOR –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏
        print("\nüîÄ XOR –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ...")
        sample_size = min(100000, len(data))  # –ë–µ—Ä–µ–º –æ–±—Ä–∞–∑–µ—Ü
        sample_data = data[:sample_size]
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º XOR —Å —Ä–∞–∑–Ω—ã–º–∏ –æ–¥–Ω–æ–±–∞–π—Ç–æ–≤—ã–º–∏ –∫–ª—é—á–∞–º–∏
        for xor_key in range(1, 256):
            try:
                decoded_bytes = bytes(b ^ xor_key for b in sample_data)
                # –ò—â–µ–º ASCII —Å—Ç—Ä–æ–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
                current_string = ""
                strings_found = []
                
                for byte in decoded_bytes:
                    if 32 <= byte <= 126:  # Printable ASCII
                        current_string += chr(byte)
                    else:
                        if len(current_string) >= 16:
                            strings_found.append(current_string)
                        current_string = ""
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                for s in strings_found[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
                    if any(keyword in s.lower() for keyword in ['cunba', 'key', 'secret', 'unlock']):
                        candidates.add(s)
                        print(f"   XOR(0x{xor_key:02x}): {s}")
                        
            except:
                continue
        
        print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(candidates)} —Å–∫—Ä—ã—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return list(candidates)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–∫—Ä—ã—Ç—ã—Ö —Å—Ç—Ä–æ–∫: {e}")
        return []

def analyze_data_segments():
    """–ê–Ω–∞–ª–∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤ ELF —Ñ–∞–π–ª–µ"""
    print("\nüìä –ê–ù–ê–õ–ò–ó –°–ï–ì–ú–ï–ù–¢–û–í –î–ê–ù–ù–´–•")
    print("="*50)
    
    candidates = set()
    
    try:
        with open("unlock", "rb") as f:
            data = f.read()
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏
        # –ò—â–µ–º –æ–±–ª–∞—Å—Ç–∏ —Å –≤—ã—Å–æ–∫–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–µ–π
        chunk_size = 64
        high_entropy_chunks = []
        
        for i in range(0, len(data) - chunk_size, chunk_size):
            chunk = data[i:i+chunk_size]
            
            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Å—Ç—É—é —ç–Ω—Ç—Ä–æ–ø–∏—é
            byte_counts = {}
            for byte in chunk:
                byte_counts[byte] = byte_counts.get(byte, 0) + 1
            
            entropy = 0
            for count in byte_counts.values():
                probability = count / len(chunk)
                if probability > 0:
                    entropy -= probability * (probability.bit_length() - 1)
            
            # –ò—â–µ–º —á–∞–Ω–∫–∏ —Å –≤—ã—Å–æ–∫–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–µ–π
            if entropy > 4.0:  # –í—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è
                try:
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                    text = chunk.decode('ascii', errors='ignore')
                    if len(text) >= 16 and text.isprintable():
                        high_entropy_chunks.append((i, text, entropy))
                except:
                    pass
        
        high_entropy_chunks.sort(key=lambda x: x[2], reverse=True)
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(high_entropy_chunks)} —á–∞–Ω–∫–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–µ–π")
        
        for offset, text, entropy in high_entropy_chunks[:10]:
            print(f"   0x{offset:08x}: —ç–Ω—Ç—Ä–æ–ø–∏—è {entropy:.2f} - {text[:50]}")
            candidates.add(text.strip())
        
        return list(candidates)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {e}")
        return []

def find_constant_pools():
    """–ü–æ–∏—Å–∫ –ø—É–ª–æ–≤ –∫–æ–Ω—Å—Ç–∞–Ω—Ç –∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüéØ –ü–û–ò–°–ö –ü–£–õ–û–í –ö–û–ù–°–¢–ê–ù–¢")
    print("="*50)
    
    candidates = set()
    
    try:
        with open("unlock", "rb") as f:
            data = f.read()
        
        # –ò—â–µ–º NULL-terminated strings
        null_strings = []
        current_string = b""
        
        for i, byte in enumerate(data):
            if byte == 0:  # NULL terminator
                if len(current_string) >= 8:
                    try:
                        text = current_string.decode('ascii')
                        if text.isprintable():
                            null_strings.append((i - len(current_string), text))
                    except:
                        pass
                current_string = b""
            elif 32 <= byte <= 126:  # Printable ASCII
                current_string += bytes([byte])
            else:
                if len(current_string) >= 8:
                    try:
                        text = current_string.decode('ascii')
                        if text.isprintable():
                            null_strings.append((i - len(current_string), text))
                    except:
                        pass
                current_string = b""
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
        interesting_strings = []
        for offset, text in null_strings:
            # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–ª–∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            if any(kw in text.lower() for kw in ['key', 'secret', 'pass', 'token', 'sign', 'auth', 'cunba']):
                interesting_strings.append((offset, text))
            # –î–ª–∏–Ω–Ω—ã–µ –∞–ª—Ñ–∞–Ω—É–º–µ—Ä–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
            elif len(text) >= 16 and re.match(r'^[A-Za-z0-9+/=_-]+$', text):
                interesting_strings.append((offset, text))
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(interesting_strings)} –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö —Å—Ç—Ä–æ–∫")
        
        for offset, text in interesting_strings[:20]:
            print(f"   0x{offset:08x}: {text}")
            candidates.add(text)
        
        return list(candidates)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø—É–ª–æ–≤ –∫–æ–Ω—Å—Ç–∞–Ω—Ç: {e}")
        return []

def analyze_embedded_keys():
    """–ü–æ–∏—Å–∫ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–π —á–µ—Ä–µ–∑ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
    print("\nüîê –ü–û–ò–°–ö –í–°–¢–†–û–ï–ù–ù–´–• –ö–õ–Æ–ß–ï–ô")
    print("="*50)
    
    candidates = set()
    
    try:
        with open("unlock", "rb") as f:
            data = f.read()
        
        # 1. –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ PEM (—Ö–æ—Ç—è –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ –≤ ELF)
        pem_patterns = [
            b'-----BEGIN',
            b'-----END',
            b'PRIVATE KEY',
            b'PUBLIC KEY'
        ]
        
        for pattern in pem_patterns:
            pos = data.find(pattern)
            if pos != -1:
                print(f"   –ù–∞–π–¥–µ–Ω PEM –ø–∞—Ç—Ç–µ—Ä–Ω –≤ 0x{pos:08x}: {pattern}")
        
        # 2. –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–π –≤ –≤–∏–¥–µ –º–∞—Å—Å–∏–≤–æ–≤ –±–∞–π—Ç–æ–≤
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–∞–∫ static const unsigned char key[] = {...}
        print("\n–ü–æ–∏—Å–∫ –º–∞—Å—Å–∏–≤–æ–≤ –±–∞–π—Ç–æ–≤...")
        
        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã
        for i in range(0, len(data) - 64, 4):
            chunk = data[i:i+64]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω –º–∞—Å—Å–∏–≤–∞ (–º–Ω–æ–≥–æ –∑–∞–ø—è—Ç—ã—Ö –∏–ª–∏ –ø—Ä–æ–±–µ–ª–æ–≤)
            if chunk.count(b',') > 10 or chunk.count(b' ') > 20:
                try:
                    text = chunk.decode('ascii', errors='ignore')
                    if any(c in text for c in ['0x', '{', '}', ',']):
                        print(f"   0x{i:08x}: –≤–æ–∑–º–æ–∂–Ω—ã–π –º–∞—Å—Å–∏–≤ - {text[:50]}")
                except:
                    pass
        
        # 3. –ü–æ–∏—Å–∫ base64 –±–ª–æ–∫–æ–≤
        print("\n–ü–æ–∏—Å–∫ base64 –±–ª–æ–∫–æ–≤...")
        base64_pattern = re.compile(rb'[A-Za-z0-9+/]{40,}={0,2}')
        matches = base64_pattern.finditer(data)
        
        for match in matches:
            try:
                b64_data = match.group()
                decoded = base64.b64decode(b64_data)
                if len(decoded) >= 16:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–ª—é—á–∞
                    decoded_str = decoded.decode('ascii', errors='ignore')
                    if decoded_str.isprintable():
                        candidates.add(decoded_str)
                        print(f"   0x{match.start():08x}: base64 -> {decoded_str[:50]}")
                    else:
                        # –ú–æ–∂–µ—Ç –±—ã—Ç—å –±–∏–Ω–∞—Ä–Ω—ã–π –∫–ª—é—á
                        candidates.add(decoded.hex())
            except:
                pass
        
        # 4. –ü–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫ —Ä—è–¥–æ–º —Å "CunBA"
        print("\n–ü–æ–∏—Å–∫ –∫–ª—é—á–µ–π —Ä—è–¥–æ–º —Å 'CunBA'...")
        cunba_pattern = re.compile(rb'CunBA', re.IGNORECASE)
        matches = cunba_pattern.finditer(data)
        
        for match in matches:
            start = max(0, match.start() - 100)
            end = min(len(data), match.end() + 100)
            context = data[start:end]
            
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            context_strings = []
            current = ""
            for byte in context:
                if 32 <= byte <= 126:
                    current += chr(byte)
                else:
                    if len(current) >= 8:
                        context_strings.append(current)
                    current = ""
            
            for ctx_str in context_strings:
                if ctx_str.lower() != 'cunba' and len(ctx_str) >= 8:
                    candidates.add(ctx_str)
                    print(f"   –†—è–¥–æ–º —Å CunBA: {ctx_str}")
        
        return list(candidates)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–π: {e}")
        return []

def comprehensive_key_test():
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""
    print("\nüéØ –ö–û–ú–ü–õ–ï–ö–°–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï")
    print("="*50)
    
    all_candidates = set()
    
    # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    print("–°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤...")
    
    hidden_strings = find_hidden_strings()
    all_candidates.update(hidden_strings)
    
    data_segments = analyze_data_segments()
    all_candidates.update(data_segments)
    
    constant_pools = find_constant_pools()
    all_candidates.update(constant_pools)
    
    embedded_keys = analyze_embedded_keys()
    all_candidates.update(embedded_keys)
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º
    candidates = []
    for candidate in all_candidates:
        if isinstance(candidate, str) and len(candidate) >= 1:
            candidates.append(candidate)
    
    print(f"\nüéØ –§–ò–ù–ê–õ–¨–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï {len(candidates)} –ö–ê–ù–î–ò–î–ê–¢–û–í")
    print("="*60)
    
    tested = 0
    for candidate in candidates:
        tested += 1
        
        if tested % 100 == 0:
            print(f"–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ {tested}/{len(candidates)}...")
        
        if test_key_candidate(candidate):
            print(f"\nüéâ –ù–ê–ô–î–ï–ù SECRET_KEY!")
            print(f"–ö–ª—é—á: '{candidate}'")
            print(f"–î–ª–∏–Ω–∞: {len(candidate)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"–ò—Å—Ç–æ—á–Ω–∏–∫: —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–∏–Ω–∞—Ä–Ω–∏–∫–∞")
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
            create_final_generator(candidate)
            return candidate
    
    print(f"\n‚ùå –ö–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω —Å—Ä–µ–¥–∏ {len(candidates)} —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
    return None

def create_final_generator(secret_key):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∫–ª—é—á–æ–º"""
    generator_code = f'''#!/usr/bin/env python3
"""
–§–ò–ù–ê–õ–¨–ù–´–ô –ì–ï–ù–ï–†–ê–¢–û–† - –ö–õ–Æ–ß –ù–ê–ô–î–ï–ù –ß–ï–†–ï–ó –†–ê–°–®–ò–†–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó
"""
import jwt
from datetime import datetime

SECRET_KEY = "{secret_key}"

def generate_unlock_token(vehicle_id):
    payload = {{
        "vehicle_id": vehicle_id,
        "iss": "CunBA",
        "timestamp": int(datetime.now().timestamp())
    }}
    return jwt.encode(payload, SECRET_KEY, algorithm='HS256')

if __name__ == "__main__":
    import sys
    vehicle_id = sys.argv[1] if len(sys.argv) > 1 else input("Vehicle ID: ")
    token = generate_unlock_token(vehicle_id)
    print("="*80)
    print(token)
    print("="*80)
'''
    
    with open("D:/vzlom/final_found_generator.py", "w", encoding="utf-8") as f:
        f.write(generator_code)
    
    print(f"\n‚úÖ –°–æ–∑–¥–∞–Ω final_found_generator.py —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∫–ª—é—á–æ–º!")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üî¨ ADVANCED BINARY ANALYZER")
    print("="*80)
    print("–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–∫—Ä—ã—Ç—ã—Ö –∏ –æ–±—Ñ—É—Å—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª—é—á–µ–π")
    print()
    
    if not os.path.exists("unlock"):
        print("‚ùå –§–∞–π–ª 'unlock' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    found_key = comprehensive_key_test()
    
    if found_key:
        print(f"\nüéâ –ú–ò–°–°–ò–Ø –í–´–ü–û–õ–ù–ï–ù–ê!")
        print(f"SECRET_KEY –Ω–∞–π–¥–µ–Ω: '{found_key}'")
    else:
        print(f"\nüí° –î–ê–õ–¨–ù–ï–ô–®–ò–ï –î–ï–ô–°–¢–í–ò–Ø:")
        print("   1. –ê–Ω–∞–ª–∏–∑ —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ (Ghidra/IDA)")
        print("   2. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ü–µ–ª–µ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ")
        print("   3. –ü–æ–∏—Å–∫ –≤ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö QNX")
        print("   4. –í–æ–∑–º–æ–∂–Ω–æ, –∫–ª—é—á –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏")

if __name__ == "__main__":
    main()
