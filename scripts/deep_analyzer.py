#!/usr/bin/env python3
"""
–£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä unlock –±–∏–Ω–∞—Ä–Ω–∏–∫–∞
–ü–æ–∏—Å–∫ –æ–±—Ñ—É—Å—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import re
import sys
import binascii
import struct
from pathlib import Path
from collections import Counter

class DeepUnlockAnalyzer:
    def __init__(self, binary_path):
        self.binary_path = Path(binary_path)
        self.binary_data = None
        
    def load_binary(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        try:
            with open(self.binary_path, 'rb') as f:
                self.binary_data = f.read()
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {self.binary_path.name} ({len(self.binary_data)} –±–∞–π—Ç)")
            return True
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
            return False
    
    def search_xor_patterns(self):
        """–ü–æ–∏—Å–∫ XOR-–æ–±—Ñ—É—Å—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫"""
        print("üîç –ü–æ–∏—Å–∫ XOR-–æ–±—Ñ—É—Å—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫...")
        
        target_strings = [b'CunBA', b'HS256', b'SECRET_KEY', b'vehicle_id']
        found_patterns = []
        
        for target in target_strings:
            for xor_key in range(1, 256):
                xored_target = bytes([b ^ xor_key for b in target])
                
                pos = 0
                while True:
                    pos = self.binary_data.find(xored_target, pos)
                    if pos == -1:
                        break
                    
                    found_patterns.append({
                        'original': target.decode(),
                        'xor_key': xor_key,
                        'offset': hex(pos),
                        'xored_bytes': binascii.hexlify(xored_target).decode()
                    })
                    pos += 1
        
        return found_patterns
    
    def search_base64_patterns(self):
        """–ü–æ–∏—Å–∫ Base64 –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("üîç –ü–æ–∏—Å–∫ Base64 –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ò—â–µ–º –¥–ª–∏–Ω–Ω—ã–µ Base64 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        base64_pattern = rb'[A-Za-z0-9+/]{20,}={0,2}'
        matches = re.finditer(base64_pattern, self.binary_data)
        
        base64_candidates = []
        for match in matches:
            try:
                encoded = match.group(0).decode('ascii')
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                while len(encoded) % 4 != 0:
                    encoded += '='
                
                import base64
                decoded = base64.b64decode(encoded)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —á—Ç–æ-—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ
                if any(keyword in decoded for keyword in [b'CunBA', b'HS256', b'jwt']):
                    base64_candidates.append({
                        'offset': hex(match.start()),
                        'encoded': encoded[:50] + ('...' if len(encoded) > 50 else ''),
                        'decoded': decoded[:100] + (b'...' if len(decoded) > 100 else b''),
                        'decoded_ascii': ''.join(chr(b) if 32 <= b <= 126 else '.' for b in decoded[:100])
                    })
            except:
                continue
        
        return base64_candidates
    
    def search_entropy_regions(self):
        """–ü–æ–∏—Å–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–µ–π (–≤–æ–∑–º–æ–∂–Ω–æ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏)"""
        print("üîç –ê–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        chunk_size = 32
        high_entropy_regions = []
        
        for i in range(0, len(self.binary_data) - chunk_size, 4):
            chunk = self.binary_data[i:i+chunk_size]
            
            # –í—ã—á–∏—Å–ª—è–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é
            byte_counts = Counter(chunk)
            entropy = 0
            import math
            for count in byte_counts.values():
                p = count / len(chunk)
                if p > 0:
                    entropy -= p * math.log2(p)
            
            # –ï—Å–ª–∏ —ç–Ω—Ç—Ä–æ–ø–∏—è –≤—ã—Å–æ–∫–∞—è –∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –æ—á–µ–≤–∏–¥–Ω–æ –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º –∫–æ–¥–æ–º
            if entropy > 6.5:  # –í—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π –∫–æ–¥ ARM64
                if not self.looks_like_arm64_code(chunk):
                    high_entropy_regions.append({
                        'offset': hex(i),
                        'entropy': round(entropy, 2),
                        'data': binascii.hexlify(chunk).decode(),
                        'ascii': ''.join(chr(b) if 32 <= b <= 126 else '.' for b in chunk)
                    })
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-10 —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å –Ω–∞–∏–≤—ã—Å—à–µ–π —ç–Ω—Ç—Ä–æ–ø–∏–µ–π
        return sorted(high_entropy_regions, key=lambda x: x['entropy'], reverse=True)[:10]
    
    def looks_like_arm64_code(self, data):
        """–ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è ARM64 –∫–æ–¥–∞"""
        if len(data) < 8:
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–∏–ø–∏—á–Ω—ã–µ ARM64 –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        common_arm64_patterns = [
            b'\\x1f\\x20\\x03\\xd5',  # nop
            b'\\xfd\\x7b',            # stp fp, lr
            b'\\xfd\\x03',            # mov fp, sp
            b'\\xe0\\x03'             # mov x0, x
        ]
        
        for pattern in common_arm64_patterns:
            if pattern in data:
                return True
        return False
    
    def search_nearby_data_sections(self):
        """–ü–æ–∏—Å–∫ –≤ —Å–µ–∫—Ü–∏—è—Ö –¥–∞–Ω–Ω—ã—Ö —Ä—è–¥–æ–º —Å –∫–æ–¥–æ–º"""
        print("üîç –ê–Ω–∞–ª–∏–∑ —Å–µ–∫—Ü–∏–π –¥–∞–Ω–Ω—ã—Ö...")
        
        if len(self.binary_data) < 64:
            return []
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ ELF –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–µ–∫—Ü–∏–π
        try:
            # –ß–∏—Ç–∞–µ–º section header offset
            shoff = struct.unpack('<Q', self.binary_data[40:48])[0]
            shentsize = struct.unpack('<H', self.binary_data[58:60])[0]
            shnum = struct.unpack('<H', self.binary_data[60:62])[0]
            
            sections = []
            for i in range(shnum):
                if shoff + i * shentsize + shentsize > len(self.binary_data):
                    break
                    
                sh_offset = shoff + i * shentsize
                sh_type = struct.unpack('<I', self.binary_data[sh_offset + 4:sh_offset + 8])[0]
                sh_addr = struct.unpack('<Q', self.binary_data[sh_offset + 16:sh_offset + 24])[0]
                sh_offset_data = struct.unpack('<Q', self.binary_data[sh_offset + 24:sh_offset + 32])[0]
                sh_size = struct.unpack('<Q', self.binary_data[sh_offset + 32:sh_offset + 40])[0]
                
                # –ò—â–µ–º —Å–µ–∫—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö (.data, .rodata, .bss)
                if sh_type in [1, 2, 8]:  # PROGBITS, SYMTAB, NOBITS
                    sections.append({
                        'index': i,
                        'type': sh_type,
                        'addr': hex(sh_addr),
                        'offset': sh_offset_data,
                        'size': sh_size
                    })
            
            return sections
        except:
            return []
    
    def search_string_table(self):
        """–ü–æ–∏—Å–∫ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö —Å—Ç—Ä–æ–∫"""
        print("üîç –ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü —Å—Ç—Ä–æ–∫...")
        
        # –ò—â–µ–º null-terminated —Å—Ç—Ä–æ–∫–∏ –¥–ª–∏–Ω–æ–π –æ—Ç 4 –¥–æ 64 —Å–∏–º–≤–æ–ª–æ–≤
        string_pattern = rb'[\x20-\x7e]{4,64}\x00'
        matches = re.finditer(string_pattern, self.binary_data)
        
        interesting_strings = []
        keywords = ['secret', 'key', 'jwt', 'token', 'hmac', 'cunba', 'vehicle']
        
        for match in matches:
            string = match.group(0)[:-1].decode('ascii', errors='ignore').lower()
            if any(keyword in string for keyword in keywords):
                interesting_strings.append({
                    'offset': hex(match.start()),
                    'string': match.group(0)[:-1].decode('ascii', errors='ignore'),
                    'length': len(match.group(0)) - 1
                })
        
        return interesting_strings
    
    def run_deep_analysis(self):
        """–ó–∞–ø—É—Å–∫ —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        print("üîç –ù–∞—á–∏–Ω–∞–µ–º —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ unlock –±–∏–Ω–∞—Ä–Ω–∏–∫–∞...")
        print("=" * 60)
        
        if not self.load_binary():
            return
        
        # 1. –ü–æ–∏—Å–∫ XOR-–æ–±—Ñ—É—Å—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        print("\nüîê 1. –ü–æ–∏—Å–∫ XOR-–æ–±—Ñ—É—Å—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫:")
        xor_patterns = self.search_xor_patterns()
        if xor_patterns:
            for pattern in xor_patterns[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                print(f"   ‚Ä¢ '{pattern['original']}' —Å XOR –∫–ª—é—á–æ–º {pattern['xor_key']} (0x{pattern['xor_key']:02x}) –≤ {pattern['offset']}")
        else:
            print("   –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # 2. –ü–æ–∏—Å–∫ Base64 –¥–∞–Ω–Ω—ã—Ö
        print("\nüî§ 2. –ü–æ–∏—Å–∫ Base64 –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        b64_patterns = self.search_base64_patterns()
        if b64_patterns:
            for pattern in b64_patterns[:5]:
                print(f"   –°–º–µ—â–µ–Ω–∏–µ: {pattern['offset']}")
                print(f"   Encoded: {pattern['encoded']}")
                print(f"   Decoded: {pattern['decoded_ascii']}")
                print()
        else:
            print("   –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # 3. –ê–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏
        print("\nüìä 3. –†–µ–≥–∏–æ–Ω—ã —Å –≤—ã—Å–æ–∫–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–µ–π (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏):")
        entropy_regions = self.search_entropy_regions()
        for region in entropy_regions[:5]:
            print(f"   –°–º–µ—â–µ–Ω–∏–µ: {region['offset']}, —ç–Ω—Ç—Ä–æ–ø–∏—è: {region['entropy']}")
            print(f"   HEX: {region['data'][:64]}...")
            print(f"   ASCII: {region['ascii'][:32]}...")
            print()
        
        # 4. –ê–Ω–∞–ª–∏–∑ —Å–µ–∫—Ü–∏–π
        print("\nüìã 4. –ê–Ω–∞–ª–∏–∑ ELF —Å–µ–∫—Ü–∏–π:")
        sections = self.search_nearby_data_sections()
        for section in sections[:5]:
            print(f"   –°–µ–∫—Ü–∏—è #{section['index']}: —Ç–∏–ø {section['type']}, –∞–¥—Ä–µ—Å {section['addr']}, —Ä–∞–∑–º–µ—Ä {section['size']}")
        
        # 5. –ü–æ–∏—Å–∫ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        print("\nüî§ 5. –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏:")
        strings = self.search_string_table()
        for string in strings[:10]:
            print(f"   {string['offset']}: '{string['string']}'")
        
        print("\n‚úÖ –£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print("\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–≥–∏–æ–Ω—ã —Å –≤—ã—Å–æ–∫–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–µ–π - –≤–æ–∑–º–æ–∂–Ω–æ, —Ç–∞–º –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏")
        print("2. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ XOR-–¥–µ–æ–±—Ñ—É—Å–∫–∞—Ü–∏—é –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
        print("3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å Frida")

def main():
    if len(sys.argv) != 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python deep_analyzer.py <–ø—É—Ç—å_–∫_unlock_—Ñ–∞–π–ª—É>")
        return
    
    analyzer = DeepUnlockAnalyzer(sys.argv[1])
    analyzer.run_deep_analysis()

if __name__ == "__main__":
    main()
